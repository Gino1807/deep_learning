{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a1ddd6",
   "metadata": {},
   "source": [
    "# Speech Regognition with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366cb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from IPython.display import Audio, display,update_display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d89b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ginovalverde/projects/deep_learning/notebooks\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.path.exists('../../.kaggle/16000_pcm_speeches/Benjamin_Netanyau/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643afbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '../../.kaggle/16000_pcm_speeches'\n",
    "BENJAMIN_DATA= os.path.join(DATASET_ROOT, \"Benjamin_Netanyau\")\n",
    "JENS_DATA= os.path.join(DATASET_ROOT, \"Jens_Stoltenberg\")\n",
    "JULIA_DATA=os.path.join(DATASET_ROOT, \"Julia_Gillard\")\n",
    "MARGARET_DATA=os.path.join(DATASET_ROOT, \"Magaret_Tarcher\")\n",
    "NELSON_DATA=os.path.join(DATASET_ROOT, \"Nelson_Mandela\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf1705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamin_Netanyau: ../../.kaggle/16000_pcm_speeches/Benjamin_Netanyau -> True\n",
      "Jens_Stoltenberg: ../../.kaggle/16000_pcm_speeches/Jens_Stoltenberg -> True\n",
      "Julia_Gillard: ../../.kaggle/16000_pcm_speeches/Julia_Gillard -> True\n",
      "Margaret_Thatcher: ../../.kaggle/16000_pcm_speeches/Margaret_Thatcher -> False\n",
      "Nelson_Mandela: ../../.kaggle/16000_pcm_speeches/Nelson_Mandela -> True\n"
     ]
    }
   ],
   "source": [
    "for name in [\"Benjamin_Netanyau\", \"Jens_Stoltenberg\", \"Julia_Gillard\", \"Margaret_Thatcher\", \"Nelson_Mandela\"]:\n",
    "    full_path = os.path.join(DATASET_ROOT, name)\n",
    "    print(f\"{name}: {full_path} -> {os.path.exists(full_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b0478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(dataset_paths):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for index, dataset in enumerate(dataset_paths):\n",
    "        print(f\"Parsing dataset {dataset}...\".format(dataset))\n",
    "        for fname in os.listdir(dataset):\n",
    "            wav,sr=librosa.load(os.path.join(dataset, fname), sr=None)\n",
    "            D=librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max)\n",
    "            X.append(D)\n",
    "            y.append(index)\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd70368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dataset ../../.kaggle/16000_pcm_speeches/Benjamin_Netanyau...\n",
      "Parsing dataset ../../.kaggle/16000_pcm_speeches/Jens_Stoltenberg...\n",
      "Parsing dataset ../../.kaggle/16000_pcm_speeches/Julia_Gillard...\n",
      "Parsing dataset ../../.kaggle/16000_pcm_speeches/Magaret_Tarcher...\n",
      "Parsing dataset ../../.kaggle/16000_pcm_speeches/Nelson_Mandela...\n"
     ]
    }
   ],
   "source": [
    "X,y =parse_dataset([BENJAMIN_DATA, JENS_DATA, JULIA_DATA, MARGARET_DATA, NELSON_DATA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb3275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7501"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ff861",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7398154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346f2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,X_val,y_test,y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce26fc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del subconjunto de entrenamiento:  6750\n",
      "Longitud del subconjunto de validación:  376\n",
      "Longitud del subconjunto de prueba:  375\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del subconjunto de entrenamiento: \", len(X_train))\n",
    "print(\"Longitud del subconjunto de validación: \", len(X_val))\n",
    "print(\"Longitud del subconjunto de prueba: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10851b98",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7cc66f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Config', 'CustomObjectScope', 'FeatureSpace', 'Progbar', 'PyDataset', 'Sequence', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'array_to_img', 'audio_dataset_from_directory', 'bounding_boxes', 'clear_session', 'custom_object_scope', 'deserialize_keras_object', 'disable_interactive_logging', 'enable_interactive_logging', 'get_custom_objects', 'get_file', 'get_registered_name', 'get_registered_object', 'get_source_inputs', 'image_dataset_from_directory', 'img_to_array', 'is_interactive_logging_enabled', 'is_keras_tensor', 'legacy', 'load_img', 'model_to_dot', 'normalize', 'pack_x_y_sample_weight', 'pad_sequences', 'plot_model', 'register_keras_serializable', 'save_img', 'serialize_keras_object', 'set_random_seed', 'split_dataset', 'standardize_dtype', 'text_dataset_from_directory', 'timeseries_dataset_from_array', 'to_categorical', 'unpack_x_y_sample_weight']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(dir(tf.keras.utils))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0baf8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def prep_dataset(X,y,shape):\n",
    "    X_prep=np.array(X).reshape((len(X),shape))\n",
    "    X_prep=X_prep.astype('float32')/255\n",
    "    y_prep=to_categorical(np.array(y))\n",
    "    return(X_prep,y_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf99981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
